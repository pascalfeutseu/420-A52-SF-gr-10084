{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**420-A52-SF - Algorithmes d'apprentissage supervisé - Automne 2022 - Spécialisation technique en Intelligence Artificielle**<br/>\n",
    "MIT License - Copyright (c) 2022 Mikaël Swawola\n",
    "<br/>\n",
    "![Travaux Pratiques - Optimisation des hyperparamètres 101](static/16-banner.png)\n",
    "<br/>\n",
    "**Objectif:** cette séance de travaux pratiques a pour objectif la recherche des meilleurs hyperparamètres appliqués à l'ensemble des algorithmes vus en cours jusqu'à maintenant. Le jeu de données utilisé sera **Titanic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 - Chargement et exploration sommaire des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('../../data/titanic_train.csv', index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Configuration de la visualisation\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5, })\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.scatterplot(x='Age', y='Survived', hue='Sex', size='Pclass', sizes=(20, 200), data=titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion des variables `embarked` et `sex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.get_dummies(titanic, columns=['Embarked'], prefix = ['emb'], drop_first=True)\n",
    "titanic['Sex'] = (titanic['Sex'] == 'female').astype(int)\n",
    "titanic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic[['Age', 'Sex','Pclass','SibSp','Parch','Fare','emb_Q','emb_S']]\n",
    "y = titanic['Survived'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vérification de la proportion des classes positives (Survided) et négatives (Died) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sum()/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation des valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs manquantes seront imputées pour l'exercice pour simplififer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean').fit(X)\n",
    "X = imp.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation du jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scale = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.3, stratify=y, random_state=2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 - Recherche sur grille"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 - Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from helpers import plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[class sklearn.linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid\n",
    "parameters = {'C':[0.01, 0.1, 1, 10, 100],\n",
    "              'l1_ratio':[0, 0.5, 1]}\n",
    "\n",
    "# Estimator\n",
    "clf_logreg = LogisticRegression(penalty='elasticnet',\n",
    "                                  max_iter=10000,\n",
    "                                  solver='saga',\n",
    "                                  n_jobs=-1,\n",
    "                                  random_state=2023)\n",
    "\n",
    "# GridSearch avec Validation croisée\n",
    "clf_logreg_grid = GridSearchCV(clf_logreg, parameters, cv=5, scoring=\"roc_auc\", verbose=1, n_jobs=-1, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logreg_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Meilleurs paramètres: {clf_logreg_grid.best_params_}')\n",
    "print(f'Meilleur score (mean CV): {clf_logreg_grid.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ré-entraînement du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inutile car refit = True\n",
    "clf_logreg_final = clf_logreg_grid.best_estimator_\n",
    "clf_logreg_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aire sous la courbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_proba_logreg = clf_logreg_final.predict_proba(X_train)[:,1]\n",
    "print(f'AUC = {roc_auc_score(y_train, y_train_pred_proba_logreg)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbe ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['Logistic Regression'] = y_train_pred_proba_logreg\n",
    "plot_roc_curve(results, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 - K plus proches voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[class sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid\n",
    "parameters = {\n",
    "    \"n_neighbors\": [5, 10, 20, 30, 40, 50],\n",
    "    \"weights\": ['uniform','distance'],\n",
    "}\n",
    "\n",
    "clf_knn = KNeighborsClassifier(algorithm=\"brute\")\n",
    "\n",
    "clf_knn_grid = GridSearchCV(clf_knn, parameters, cv=5, scoring=\"roc_auc\", verbose=1, n_jobs=-1, refit=True)\n",
    "clf_knn_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Meilleurs paramètres: {clf_knn_grid.best_params_}')\n",
    "print(f'Meilleur score (mean CV): {clf_knn_grid.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ré-entraînement du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inutile car refit = True\n",
    "clf_knn_final = clf_knn_grid.best_estimator_\n",
    "clf_knn_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aire sous la courbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_proba_knn = clf_knn_final.predict_proba(X_train)[:,1]\n",
    "print(f'AUC = {roc_auc_score(y_train, y_train_pred_proba_knn)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbe ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['KNN'] = y_train_pred_proba_knn\n",
    "plot_roc_curve(results, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 - Recherche aléatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1 - Arbres de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.fixes import loguniform\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[class sklearn.tree.DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions des paramètres\n",
    "distributions = dict(\n",
    "    criterion=['gini', 'entropy'],\n",
    "    ccp_alpha=loguniform(1e-3, 1e3),\n",
    "    max_depth=randint(2, 128))\n",
    "\n",
    "# Estimateur\n",
    "clf_tree = DecisionTreeClassifier(random_state=2023)\n",
    "\n",
    "    \n",
    "# Recherche aléatoire avec avec validation croisée\n",
    "clf_tree_rnd = RandomizedSearchCV(clf_tree, distributions, n_iter=1000, cv=5, scoring=\"roc_auc\", verbose=1, n_jobs=-1, random_state=2023, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_rnd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Meilleurs paramètres: {clf_tree_rnd.best_params_}')\n",
    "print(f'Meilleur score (mean CV): {clf_tree_rnd.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ré-entraînement du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inutile car refit = True\n",
    "clf_tree_final = clf_tree_rnd.best_estimator_\n",
    "clf_tree_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aire sous la courbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_proba_tree = clf_tree_final.predict_proba(X_train)[:,1]\n",
    "print(f'AUC = {roc_auc_score(y_train, y_train_pred_proba_tree)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbe ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Decision Tree'] = y_train_pred_proba_tree\n",
    "plot_roc_curve(results, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2 - Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[class sklearn.ensemble.BaggingClassifier(base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0)](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions des paramètres\n",
    "distributions = dict(\n",
    "    n_estimators=randint(2, 500))\n",
    "\n",
    "# Estimateur\n",
    "clf_bag = BaggingClassifier(estimator=clf_tree_final, random_state=2023)\n",
    "\n",
    "# Recherche aléatoire avec validation croisée\n",
    "clf_bag_rnd = RandomizedSearchCV(clf_bag, distributions, n_iter=100, cv=5, scoring=\"roc_auc\", verbose=1, n_jobs=-1, random_state=2023, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_bag_rnd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Meilleurs paramètres: {clf_bag_rnd.best_params_}')\n",
    "print(f'Meilleur score (mean CV): {clf_bag_rnd.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ré-entraînement du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inutile car refit = True\n",
    "clf_bag_final = clf_bag_rnd.best_estimator_\n",
    "clf_bag_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aire sous la courbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_proba_bag = clf_bag_final.predict_proba(X_train)[:,1]\n",
    "print(f'AUC = {roc_auc_score(y_train, y_train_pred_proba_bag)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbe ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Bagging (Tree)'] = y_train_pred_proba_bag\n",
    "plot_roc_curve(results, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4 - Hyperopt avec Forêts aléatoires et gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, space_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1 - Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition de l'hyperespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperspace = {\n",
    "    'n_estimators': 1 + hp.randint('n_estimators', 500),\n",
    "    'lr_rate': hp.loguniform('lr_rate', -8.0, 1.0),\n",
    "    'max_depth': 1 + hp.randint('max_depth', 100),\n",
    "    'max_features': hp.choice('max_features', ['sqrt', 'log2', None]),\n",
    "    'loss': hp.choice('loss', ['log_loss', 'exponential']),\n",
    "    'ccp_alpha': hp.loguniform('ccp_alpha', -6, 2),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(hyperspace):\n",
    "\n",
    "    lr = hyperspace['lr_rate']\n",
    "    md = hyperspace['max_depth']\n",
    "    n = hyperspace['n_estimators']\n",
    "    l = hyperspace['loss']\n",
    "    mf = hyperspace['max_features']\n",
    "    a = hyperspace['ccp_alpha']\n",
    "\n",
    "    clf_gb = GradientBoostingClassifier(loss=l, max_features=mf,\n",
    "                                                n_estimators=n, learning_rate=lr, max_depth=md,\n",
    "                                                ccp_alpha=a,\n",
    "                                                random_state=2023)\n",
    "    clf_gb.fit(X_train, y_train)\n",
    "    cv_score = cross_val_score(clf_gb, X_train, y_train, cv=5, scoring=\"roc_auc\", verbose=0, n_jobs=-1)\n",
    "\n",
    "    return -cv_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lancement de l'optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fmin(objective, hyperspace, algo=tpe.suggest, max_evals=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meilleurs paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réentraînement du gradient boosting avec les meilleurs hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gb_final = GradientBoostingClassifier(loss='exponential', max_features='log2',\n",
    "                                                n_estimators=301, learning_rate=0.26973180768518795, max_depth=36,\n",
    "                                                ccp_alpha=0.0036803454953677865,\n",
    "                                                random_state=2023)\n",
    "clf_gb_final.fit(X_train, y_train)\n",
    "cv_score = cross_val_score(clf_gb_final, X_train, y_train, cv=5, scoring=\"roc_auc\", verbose=0, n_jobs=-1)\n",
    "cv_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aire sous la courbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_proba_gb = clf_gb_final.predict_proba(X_train)[:,1]\n",
    "print(f'AUC = {roc_auc_score(y_train, y_train_pred_proba_gb)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbe ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Gradient Boosting'] = y_train_pred_proba_gb\n",
    "plot_roc_curve(results, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2 - Gradient boosting et forêts aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de l'hyperespace\n",
    "\n",
    "hyperspace = hp.choice('classifier',[\n",
    "    {\n",
    "        'type': 'gradient-boosting',\n",
    "        'n_estimators': 1 + hp.randint('n_estimators_1', 100),\n",
    "        'lr_rate': hp.loguniform('lr_rate', -8, 1),\n",
    "        'max_depth': 1 + hp.randint('max_depth', 100),\n",
    "        'max_features': hp.choice('max_features1', ['sqrt', 'log2', None]),\n",
    "        'loss': hp.choice('loss', ['log_loss', 'exponential']),\n",
    "        'ccp_alpha': hp.loguniform('ccp_alpha1', -6, 2)\n",
    "    },\n",
    "    {\n",
    "        'type': 'random-forests',\n",
    "        'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "        'n_estimators': 1 + hp.randint('n_estimators_2', 500),\n",
    "        'max_features': hp.choice('max_features2', ['sqrt', 'log2', None]),\n",
    "        'ccp_alpha': hp.loguniform('ccp_alpha2', -6, 2)\n",
    "    }\n",
    "])\n",
    "\n",
    "# Fonction objective\n",
    "\n",
    "def objective(hyperspace):\n",
    "\n",
    "    if hyperspace['type'] == 'gradient-boosting':\n",
    "        lr = hyperspace['lr_rate']\n",
    "        md = hyperspace['max_depth']\n",
    "        n = hyperspace['n_estimators']\n",
    "        l = hyperspace['loss']\n",
    "        mf = hyperspace['max_features']\n",
    "        a = hyperspace['ccp_alpha']\n",
    "\n",
    "        clf_gb = GradientBoostingClassifier(loss=l, max_features=mf,\n",
    "                                            n_estimators=n, learning_rate=lr, max_depth=md,\n",
    "                                            ccp_alpha=a,\n",
    "                                            random_state=2023)\n",
    "        clf_gb.fit(X_train, y_train)\n",
    "        cv_score = cross_val_score(clf_gb, X_train, y_train, cv=5, scoring=\"roc_auc\", verbose=0, n_jobs=-1)\n",
    "\n",
    "        return -cv_score.mean()\n",
    "    elif hyperspace['type'] == 'random-forests':\n",
    "        c = hyperspace['criterion']\n",
    "        n = hyperspace['n_estimators']\n",
    "        mf = hyperspace['max_features']\n",
    "        a = hyperspace['ccp_alpha']\n",
    "        \n",
    "        clf_rf = RandomForestClassifier(criterion=c, n_estimators=n, max_features=mf, ccp_alpha=a,\n",
    "                                        random_state=2023,\n",
    "                                        n_jobs=-1)\n",
    "        clf_rf.fit(X_train, y_train)\n",
    "        cv_score = cross_val_score(clf_rf, X_train, y_train, cv=5, scoring=\"roc_auc\", verbose=0, n_jobs=-1)\n",
    "\n",
    "        return -cv_score.mean()\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "        return None\n",
    "\n",
    "# Lancement de l'optimisation\n",
    "\n",
    "best = fmin(objective, hyperspace, algo=tpe.suggest, max_evals=1000)\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réentraînement du meilleur algorithme avec les meilleurs hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf_final = RandomForestClassifier(max_features='log2',\n",
    "                                                n_estimators=83,\n",
    "                                                ccp_alpha=0.0024827110880081497,\n",
    "                                                criterion='gini',\n",
    "                                                random_state=2023)\n",
    "clf_rf_final.fit(X_train, y_train)\n",
    "cv_score = cross_val_score(clf_rf_final, X_train, y_train, cv=5, scoring=\"roc_auc\", verbose=0, n_jobs=-1)\n",
    "cv_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aire sous la courbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_proba_rf = clf_rf_final.predict_proba(X_train)[:,1]\n",
    "print(f'AUC = {roc_auc_score(y_train, y_train_pred_proba_rf)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbe ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Random Forests'] = y_train_pred_proba_rf\n",
    "plot_roc_curve(results, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 5 - Sélection du modèle et performances sur le jeu de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Modèle | AUC (CV) | AUC (refit)\n",
    "| ------ | ------ | ------\n",
    "| Régression logisitique | 0.8615   | 0.8669  \n",
    "| KNN |0.8616 | 0.8952\n",
    "| Arbres de classification | 0.8648 | 0.8956\n",
    "| Bagging (Arbres) | 0.8697 | 0.9121\n",
    "| Gradient Boosting | <span style=\"color:red\">0.8817</span>| <span style=\"color:red\">0.9795</span>\n",
    "| Forêts aléatoires | 0.8789  | 0.9730"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aire sous la courbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_proba_best = clf_gb_final.predict_proba(X_test)[:,1]\n",
    "print(f'AUC = {roc_auc_score(y_test, y_test_pred_proba_best)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbe ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = {}\n",
    "results_test['BEST'] = y_test_pred_proba_best\n",
    "plot_roc_curve(results_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
